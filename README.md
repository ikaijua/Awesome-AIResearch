This repo collects AI-related research. 

### Spatial Intelligence
| Name | Description | Links | Publish Time|
| ---- | ----------------------------- | --- | --- |
|Behavior Vision Suite|BEHAVIOR Vision Suite: Customizable Dataset Generation via Simulation|[Project website](https://behavior-vision-suite.github.io/)|2024|

### Robot

| Name | Description | Links | Publish Time|
| ---- | ----------------------------- | --- | --- |
|huggingface/lerobot|State-of-the-art Machine Learning for Real-World Robotics in Pytorch|[Github](https://github.com/huggingface/lerobot) ![GitHub Repo stars](https://img.shields.io/github/stars/huggingface/lerobot?style=social)|2024|
| TidyBot | A household cleanup robot done by [StanfordAILab](https://twitter.com/StanfordAILab).|[GitHub](https://github.com/jimmyyhwu/tidybot) ![GitHub Repo stars](https://img.shields.io/github/stars/jimmyyhwu/tidybot?style=social) | 2023 |
| Eureka | Human-Level Reward Design via Coding Large Language Models, such as GPT-4, to perform in-context evolutionary optimization over reward code. Harnessing them to learn complex low-level manipulation tasks, such as dexterous pen spinning |[Github](https://github.com/eureka-research/Eureka) ![GitHub Repo stars](https://img.shields.io/github/stars/eureka-research/Eureka?style=social)|2023|
| NOIR | Neural Signal Operated Intelligent Robots for Everyday Activities. Stanford University | [Project website](https://noir-corl.github.io/)|2023|
| robotics-survey/Awesome-Robotics-Foundation-Models | This repository is largely based on the following paper: [Foundation Models in Robotics: Applications, Challenges, and the Future](https://arxiv.org/pdf/2312.07843.pdf)  By Stanford University, Princeton University, UT Austin, NVIDIA, Scaled Foundations, Google DeepMind, TU Berlin, Shanghai Jiao Tong University| [Github](https://github.com/robotics-survey/Awesome-Robotics-Foundation-Models) ![GitHub Repo stars](https://img.shields.io/github/stars/robotics-survey/Awesome-Robotics-Foundation-Models?style=social)|2023|
| JeffreyYH/robotics-fm-survey | Survey Paper of foundation models for robotics. paper: [oward General-Purpose Robots via Foundation Models: A Survey and Meta-Analysis](https://arxiv.org/abs/2312.08782) By CMU, Bosch Center for AI, SAIR Lab, Georgia Tech, FAIR at Meta, UC San Diego, Google DeepMind |[Github](https://github.com/JeffreyYH/robotics-fm-survey) ![GitHub Repo stars](https://img.shields.io/github/stars/JeffreyYH/robotics-fm-survey?style=social)|2023|

### Multi-modal LLM
| Name | Description | Links | Publish Time|
| ---- | ----------------------------- | --- | --- |
| mPLUG-DocOwl | Modularized Multimodal Large Language Model for Document Understanding. By Alibaba Group | [Github](https://github.com/X-PLUG/mPLUG-DocOwl) ![GitHub Repo stars](https://img.shields.io/github/stars/X-PLUG/mPLUG-DocOwl?style=social)|2024|

### Vision-Language (VL) Model
| Name | Description | Links | Publish Time|
| ---- | ----------------------------- | --- | --- |
|DeepSeek-VL|An open-source Vision-Language (VL) Model designed for real-world vision and language understanding applications. DeepSeek-VL possesses general multimodal understanding capabilities, capable of processing logical diagrams, web pages, formula recognition, scientific literature, natural images, and embodied intelligence in complex scenarios.|[Github](https://github.com/deepseek-ai/DeepSeek-VL) ![GitHub Repo stars](https://img.shields.io/github/stars/deepseek-ai/DeepSeek-VL?style=social)|2024|
|An Introduction to Vision-Language Modeling|An Introduction to Vision-Language Modeling. By Meta.|[URL](https://arxiv.org/abs/2405.17247)|2024|
### Brain Computer Interface

| Name | Description | Links | Publish Time|
| ---- | ----------------------------- | --- | --- |
|TBC-TJU/MetaBCI|China’s first open-source platform for non-invasive brain computer interface. The project of MetaBCI is led by Prof. Minpeng Xu from Tianjin University, China.|[Github](https://github.com/TBC-TJU/MetaBCI) ![GitHub Repo stars](https://img.shields.io/github/stars/TBC-TJU/MetaBCI?style=social)|2022|

### LLM Datasets
| Name | Description | Links | Publish Time|
|----|----|---|---|
|Awesome-LLMs-Datasets|Summarize existing representative LLMs text datasets.|[Github](https://github.com/lmmlzn/Awesome-LLMs-Datasets) ![GitHub Repo stars](https://img.shields.io/github/stars/lmmlzn/Awesome-LLMs-Datasets?style=social)|2024|

### LMMs Benchmark
| Name | Description | Links | Publish Time|
| ---- | ----------------------------- | --- | --- |
| mathvista | A benchmark designed to combine challenges from diverse mathematical and visual tasks. By UCLA and Microsoft Research| [Project website](https://mathvista.github.io/)| 2023|
| hallucination-leaderboard | Leaderboard Comparing LLM Performance at Producing Hallucinations when Summarizing Short Documents. |[Github](https://github.com/vectara/hallucination-leaderboard) ![GitHub Repo stars](https://img.shields.io/github/stars/vectara/hallucination-leaderboard?style=social)| 2023 |
| GAIA| A benchmark for General AI Assistants. By Meta-FAIR, Meta-GenAI, HuggingFace and AutoGPT|[Project website](https://huggingface.co/papers/2311.12983)|2023|
|microsoft/promptbench|A Unified Library for Evaluating and Understanding Large Language Models.|[Github](https://github.com/microsoft/promptbench) ![GitHub Repo stars](https://img.shields.io/github/stars/microsoft/promptbench?style=social)|2023|

### Summarization
| Name | Description | Links | Publish Time|
| ---- | ----------------------------- | --- | --- |
| Summarization is (Almost) Dead | Our findings indicate a clear preference among human evaluators for LLM-generated summaries over human-written summaries and summaries generated by fine-tuned models. | https://arxiv.org/pdf/2309.09558.pdf | 2023|

### TTS
| Name | Description | Links | Publish Time|
| ---- | ----------------------------- | --- | --- |
|VoiceCraft|VoiceCraft is a token infilling neural codec language model, that achieves state-of-the-art performance on both speech editing and zero-shot text-to-speech (TTS) on in-the-wild data including audiobooks, internet videos, and podcasts.To clone or edit an unseen voice, VoiceCraft needs only a few seconds of reference.|[Github](https://github.com/jasonppy/VoiceCraft) ![GitHub Repo stars](https://img.shields.io/github/stars/jasonppy/VoiceCraft?style=social)|2024|
| Mega-TTS 2 | Input text and reference audio, clone the timbre of the reference audio to generate speech corresponding to the text. By Zhejiang University and ByteDance. Paper：https://arxiv.org/abs/2307.07218|[URL](https://boostprompt.github.io/boostprompt/)|2024|
| NaturalSpeech 3 |Zero-Shot Speech Synthesis with Factorized Codec and Diffusion Models. By Microsoft Research Asia <br>paper: https://arxiv.org/abs/2403.03100|[URL](https://speechresearch.github.io/naturalspeech3/)|2024|
| BASE TTS | BASE TTS is the largest TTS model to-date, trained on 100K hours of public domain speech data, achieving a new state-of-the-art in speech naturalness. By amazon. <br>paper:https://arxiv.org/abs/2402.08093|[URL](https://amazon-ltts-paper.com/)|2024|
| metavoice-src |Foundational model for human-like, expressive TTS. Zero-shot cloning for American & British voices, with 30s reference audio. |[Github](https://github.com/metavoiceio/metavoice-src) ![GitHub Repo stars](https://img.shields.io/github/stars/metavoiceio/metavoice-src?style=social) |2024|
| Bark | Multilingual <br> Demo: https://huggingface.co/spaces/suno/bark <br>Paper: https://arxiv.org/abs/2209.03143 |[Github](https://github.com/suno-ai/bark) ![GitHub Repo stars](https://img.shields.io/github/stars/suno-ai/bark?style=social) | 2023 |
| XTTS | Multilingual <br> Demo: https://huggingface.co/spaces/coqui/xtts | [Github](https://github.com/coqui-ai/TTS) ![GitHub Repo stars](https://img.shields.io/github/stars/coqui-ai/TTS?style=social)| 2021 |
| OpenVoice | ZH + EN <br>Demo: https://huggingface.co/spaces/myshell-ai/OpenVoice <br>Paper: https://arxiv.org/abs/2312.01479|[Github](https://github.com/myshell-ai/OpenVoice) ![GitHub Repo stars](https://img.shields.io/github/stars/myshell-ai/OpenVoice?style=social)| 2023 |
| TorToiSe TTS |English <br>Demo: https://huggingface.co/spaces/Manmay/tortoise-tts <br>Paper:https://arxiv.org/abs/2305.07243 |[Github](https://github.com/neonbjb/tortoise-tts)  ![GitHub Repo stars](https://img.shields.io/github/stars/neonbjb/tortoise-tts?style=social) | 2022 |
| GPT-SoVITS | Multilingual |[Github](https://github.com/RVC-Boss/GPT-SoVITS) ![GitHub Repo stars](https://img.shields.io/github/stars/RVC-Boss/GPT-SoVITS?style=social)| | 2024|
| EmotiVoice | ZH + EN |[Github](https://github.com/netease-youdao/EmotiVoice) ![GitHub Repo stars](https://img.shields.io/github/stars/netease-youdao/EmotiVoice?style=social) | 2023 |
| MeloTTS | high-quality multi-lingual text-to-speech library by MyShell.ai. Support English, Spanish, French, Chinese, Japanese and Korean.|[Github](https://github.com/myshell-ai/MeloTTS) ![GitHub Repo stars](https://img.shields.io/github/stars/myshell-ai/MeloTTS?style=social)| 2024|
| Tacotron 2 |English <br> Paper: https://arxiv.org/abs/1712.05884|Unofficial Repo:[Github](https://github.com/NVIDIA/tacotron2) ![GitHub Repo stars](https://img.shields.io/github/stars/NVIDIA/tacotron2?style=social) | [GDrive](https://drive.google.com/file/d/1c5ZTuT7J08wLUoVZ2KkUs_VdZuJ86ZqA/view) | [BSD-3](https://github.com/NVIDIA/tacotron2/blob/master/LICENSE) | [Yes](https://github.com/NVIDIA/tacotron2/tree/master?tab=readme-ov-file#training) |  | [Paper]() | [Webpage](https://google.github.io/tacotron/publications/tacotron2/) | 2018 |
| Silero | EM + DE + ES + EA| [Github](https://github.com/snakers4/silero-models) ![GitHub Repo stars](https://img.shields.io/github/stars/snakers4/silero-models?style=social)  | |2020|
| StyleTTS 2 | English <br> Demo: https://huggingface.co/spaces/styletts2/styletts2 <br>Paper:https://arxiv.org/abs/2306.07691 |[Github](https://github.com/yl4579/StyleTTS2) ![GitHub Repo stars](https://img.shields.io/github/stars/yl4579/StyleTTS2?style=social)  | 2023 |
| Amphion | Demo: https://huggingface.co/amphion <br>Paper: https://arxiv.org/abs/2312.09911 |[Github](https://github.com/open-mmlab/Amphion) ![GitHub Repo stars](https://img.shields.io/github/stars/open-mmlab/Amphion?style=social)| 2023 |
| VALL-E | <br>Paper: https://arxiv.org/abs/2301.02111 | Unofficial Repo:[Github](https://github.com/enhuiz/vall-e) ![GitHub Repo stars](https://img.shields.io/github/stars/enhuiz/vall-e?style=social) | 2023 |
| Piper |Multilingual| [Github](https://github.com/rhasspy/piper) ![GitHub Repo stars](https://img.shields.io/github/stars/rhasspy/piper?style=social)|| 2023 |
| WhisperSpeech |English, Polish <br> [Demo](https://colab.research.google.com/github/collabora/WhisperSpeech/blob/8168a30f26627fcd15076d10c85d9e33c52204cf/Inference%20example.ipynb)| [Github](https://github.com/collabora/WhisperSpeech) ![GitHub Repo stars](https://img.shields.io/github/stars/collabora/WhisperSpeech?style=social) | 2023 |
| HierSpeech++ |KR + EN <br>Demo:https://huggingface.co/spaces/LeeSangHoon/HierSpeech_TTS <br>Paper:https://arxiv.org/abs/2311.12454 |[Github](https://github.com/sh-lee-prml/HierSpeechpp) ![GitHub Repo stars](https://img.shields.io/github/stars/sh-lee-prml/HierSpeechpp?style=social) | 2023|
| Glow-TTS |English <br>Demo:https://jaywalnut310.github.io/glow-tts-demo/index.html <br>Paper:https://arxiv.org/abs/2005.11129 | [Github](https://github.com/jaywalnut310/glow-tts) ![GitHub Repo stars](https://img.shields.io/github/stars/jaywalnut310/glow-tts?style=social) |2020|
| xVASynth | Multilingual <br>Demo:https://store.steampowered.com/app/1765720/xVASynth/  <br> Paper:https://arxiv.org/abs/2009.14153 | [Github](https://github.com/DanRuta/xVA-Synth) ![GitHub Repo stars](https://img.shields.io/github/stars/DanRuta/xVA-Synth?style=social) | 2023 |
| IMS-Toucan |  Multilingual, <br>Demo: https://huggingface.co/spaces/Flux9665/IMS-Toucan <br>Paper: https://arxiv.org/abs/2206.12229| [Github](https://github.com/DigitalPhonetics/IMS-Toucan) ![GitHub Repo stars](https://img.shields.io/github/stars/DigitalPhonetics/IMS-Toucan?style=social)| 2023 |
| Matcha-TTS |English <br>Demo:https://huggingface.co/spaces/shivammehta25/Matcha-TTS <br>Paper:https://arxiv.org/abs/2309.03199 |[Repo](https://github.com/shivammehta25/Matcha-TTS) ![GitHub Repo stars](https://img.shields.io/github/stars/shivammehta25/Matcha-TTS?style=social)| 2023|
| RAD-TTS | English <br>Paper:https://openreview.net/pdf?id=0NQwnnwAORi |[Github](https://github.com/NVIDIA/radtts) ![GitHub Repo stars](https://img.shields.io/github/stars/NVIDIA/radtts?style=social) | 2022 |
| MahaTTS |English + Indic <br>Demo: [Colab](https://colab.research.google.com/drive/1qkZz2km-PX75P0f6mUb2y5e-uzub27NW?usp=sharing)| [Github](https://github.com/dubverse-ai/MahaTTS) ![GitHub Repo stars](https://img.shields.io/github/stars/dubverse-ai/MahaTTS?style=social)  | 2023 |
| Neural-HMM TTS | English <br>Demo:https://shivammehta25.github.io/Neural-HMM/ <br>Paper:https://arxiv.org/abs/2108.13320|[Repo](https://github.com/shivammehta25/Neural-HMM) ![GitHub Repo stars](https://img.shields.io/github/stars/shivammehta25/Neural-HMM?style=social)| 2021 |
| pflowTTS |English <br>Paper:https://openreview.net/pdf?id=zNA7u7wtIN| [Unofficial Repo](https://github.com/p0p4k/pflowtts_pytorch) ![GitHub Repo stars](https://img.shields.io/github/stars/p0p4k/pflowtts_pytorch?style=social)  | 2023 |
| Pheme | English <br> Demo:https://huggingface.co/spaces/PolyAI/pheme <br>Paper:https://arxiv.org/abs/2401.02839|[Github](https://github.com/PolyAI-LDN/pheme) ![GitHub Repo stars](https://img.shields.io/github/stars/PolyAI-LDN/pheme?style=social)  | 2024 |
| TTTS |ZH <br>Demo:https://colab.research.google.com/github/adelacvg/ttts/blob/master/demo.ipynb | [Github](https://github.com/adelacvg/ttts) ![GitHub Repo stars](https://img.shields.io/github/stars/adelacvg/ttts?style=social)| | 2023 |
| VITS/ MMS-TTS |English <br> Demo:https://huggingface.co/spaces/kakao-enterprise/vits <br>Paper:https://arxiv.org/abs/2106.06103 |[Github](https://github.com/huggingface/transformers/tree/7142bdfa90a3526cfbed7483ede3afbef7b63939/src/transformers/models/vits)  | 2021|
| OverFlow TTS |English <br>Demo:https://shivammehta25.github.io/OverFlow/ <br>Paper: https://arxiv.org/abs/2211.06892|[Github](https://github.com/shivammehta25/OverFlow) ![GitHub Repo stars](https://img.shields.io/github/stars/shivammehta25/OverFlow?style=social) | 2022  |


### Image Generage
| Name | Description | Links | Publish Time|
| ---- | ----------------------------- | --- | --- |
| AnyText |Multilingual Visual Text Generation And Editing. By Alibaba Group|[Github](https://github.com/tyxsspa/AnyText) ![GitHub Repo stars](https://img.shields.io/github/stars/tyxsspa/AnyText?style=social)|2023|
|InstantID| InstantID is a new state-of-the-art tuning-free method to achieve ID-Preserving generation with only single image, supporting various downstream tasks.|[Github](https://github.com/InstantID/InstantID) ![GitHub Repo stars](https://img.shields.io/github/stars/InstantID/InstantID?style=social)|2023|
| apple/ml-mgie | Guiding Instruction-based Image Editing via Multimodal Large Language Models. By Apple.| [Github](https://github.com/apple/ml-mgie) ![GitHub Repo stars](https://img.shields.io/github/stars/apple/ml-mgie?style=social)| 2024 |
|lllyasviel/IC-Light|IC-Light is a project to manipulate the illumination of images. Demo：https://huggingface.co/spaces/lllyasviel/IC-Light|[Github](https://github.com/lllyasviel/IC-Light) ![GitHub Repo stars](https://img.shields.io/github/stars/lllyasviel/IC-Light?style=social)|2024|

### Video Generate
| Name | Description | Links | Publish Time|
| ---- | ----------------------------- | --- | --- |
|MusePose|MusePose is a diffusion-based and pose-guided virtual human video generation framework.By Tencent.|[Github](https://github.com/TMElyralab/MusePose) ![GitHub Repo stars](https://img.shields.io/github/stars/TMElyralab/MusePose?style=social)|2024|
| ProPainter |Improving Propagation and Transformer for Video Inpainting. S-Lab, Nanyang Technological University|[Github](https://github.com/sczhou/ProPainter) ![GitHub Repo stars](https://img.shields.io/github/stars/sczhou/ProPainter?style=social)|2023|
| Emu Edit/Emu video| Emu Edit is an AI generated image model that supports modifying local content of images through text; Emu Video is an AI generated video model that also supports text modification of local content in videos.|[Project website](https://ai.meta.com/blog/emu-text-to-video-generation-image-editing-research/)|2023|
| PixelDance | A novel approach based on diffusion models that incorporates image instructions for both the first and last frames in conjunction with text instructions for video generation. By ByteDance Research | [Project website](https://makepixelsdance.github.io/)|2023|
| MagicDance | Realistic Human Dance Video Generation with Motions & Facial Expressions Transfer. By University of Southern California| [Github](https://github.com/Boese0601/MagicDance) ![GitHub Repo stars](https://img.shields.io/github/stars/Boese0601/MagicDance?style=social)| 2023 | 
| TencentARC/ MotionCtrl|A Unified and Flexible Motion Controller for Video Generation|[Github](https://github.com/TencentARC/MotionCtrl) ![GitHub Repo stars](https://img.shields.io/github/stars/TencentARC/MotionCtrl?style=social)| 2023 |
| DreaMoving |A Human Video Generation Framework based on Diffusion Models. By Alibaba Group|[Github](https://github.com/dreamoving/dreamoving-project)  ![GitHub Repo stars](https://img.shields.io/github/stars/dreamoving/dreamoving-project?style=social)|2023|
| magicvideov2|Multi-Stage High-Aesthetic Video Generation by ByteDance|[URL](https://magicvideov2.github.io/)|2024|
| Boximator |Generating Rich and Controllable Motions for Video Synthesis. By ByteDance|[URL](https://boximator.github.io/)|2024|
| fudan-generative-vision/champ | Controllable and Consistent Human Image Animation with 3D Parametric Guidance | [Github](https://github.com/fudan-generative-vision/champ) ![GitHub Repo stars](https://img.shields.io/github/stars/fudan-generative-vision/champ?style=social) |2024|
| TaoHuUMD/SurMo |Surface-based 4D Motion Modeling for Dynamic Human|[Github](https://github.com/TaoHuUMD/SurMo) ![GitHub Repo stars](https://img.shields.io/github/starsTaoHuUMD/SurMo?style=social)|2024|

### Talking Face Synthesis
| Name | Description | Links | Publish Time|
| ---- | ----------------------------- | --- | --- |
|V-Express|V-Express aims to generate a talking head video under the control of a reference image, an audio, and a sequence of V-Kps images. By Tencent.|[Github](https://github.com/tencent-ailab/V-Express) ![GitHub Repo stars](https://img.shields.io/github/stars/tencent-ailab/V-Express?style=social)|2024|
|InstructAvatar|InstructAvatar: Text-Guided Emotion and Motion Control for Avatar Generation. By Peking University|[Project website](https://wangyuchi369.github.io/InstructAvatar/)|2024|
|X-LANCE/AniTalker|Animate Vivid and Diverse Talking Faces through Identity-Decoupled Facial Motion Encoding|[Github](https://github.com/X-LANCE/AniTalker) ![GitHub Repo stars](https://img.shields.io/github/stars/X-LANCE/AniTalker?style=social)|2024|
|VASA-1|Lifelike Audio-Driven Talking Faces Generated in Real Time. By Microsoft. paper:https://arxiv.org/abs/2404.10667|[Project Website](https://www.microsoft.com/en-us/research/project/vasa-1/)|2024|
| GeneFace | Generalized and High-Fidelity 3D Talking Face Synthesis.  Zhejiang University, ByteDance |[Github](https://github.com/yerfor/GeneFace) ![GitHub Repo stars](https://img.shields.io/github/stars/yerfor/GeneFace?style=social)|2023|
|GAIA|Zero-shot talking avatar generation aims at synthesizing natural talking videos from speech and a single portrait image. GAIA (Generative AI for Avatar), which eliminates the domain priors in talking avatar generation. By Microsoft|[Project Website](https://microsoft.github.io/GAIA/)|2023|

### Video Comprehensio
| Name | Description | Links | Publish Time|
| ---- | ----------------------------- | --- | --- |
|PKU-YuanGroup/Video-LLaVA| Video-LLaVA: Learning United Visual Representation by Alignment Before Projection | [Github](https://github.com/PKU-YuanGroup/Video-LLaVA) ![GitHub Repo stars](https://img.shields.io/github/stars/PKU-YuanGroup/Video-LLaVA?style=social)|2023|

### Data Cleaning
| Name | Description | Links | Publish Time|
| ---- | ----------------------------- | --- | --- |
| cleanlab | The standard data-centric AI package for data quality and machine learning with messy, real-world data and labels. |[Github](https://github.com/cleanlab/cleanlab) ![GitHub Repo stars](https://img.shields.io/github/stars/cleanlab/cleanlab?style=social)||

### 3D Generate 
| Name | Description | Links | Publish Time|
| ---- | ----------------------------- | --- | --- |
| DMV3D | Denoising Multi-View Diffusion using 3D Large Reconstruction Model. A single-stage approach for high-quality text-to-3D generation and single-image reconstruction in 30s. By Adobe, Stanford, etc|[Project website](https://justimyhxu.github.io/projects/dmv3d/)|2023|
| Make-A-Character | High Quality Text-to-3D Character Generation within Minutes. By Alibaba| [Github](https://github.com/Human3DAIGC/Make-A-Character) ![GitHub Repo stars](https://img.shields.io/github/stars/Human3DAIGC/Make-A-Character?style=social)|2023|

### Object Dectection
| Name | Description | Links | Publish Time|
| ---- | ----------------------------- | --- | --- |
|open-mmlab/mmdetection|MMDetection is an open source object detection toolbox based on PyTorch. |[Github](https://github.com/open-mmlab/mmdetection) ![GitHub Repo stars](https://img.shields.io/github/stars/open-mmlab/mmdetection?style=social)||
|AILab-CVC/YOLO-World|Real-Time Open-Vocabulary Object Detection. By Tencent. |[Github](https://github.com/AILab-CVC/YOLO-World) ![GitHub Repo stars](https://img.shields.io/github/stars/AILab-CVC/YOLO-World?style=social)|2024|
|LiheYoung/Depth-Anything|Depth Anything: Unleashing the Power of Large-Scale Unlabeled Data. Foundation Model for Monocular Depth Estimation. By 1The University of Hong Kong · 2TikTok · 3Zhejiang Lab · 4Zhejiang University|[Github](https://github.com/LiheYoung/Depth-Anything) ![GitHub Repo stars](https://img.shields.io/github/stars/LiheYoung/Depth-Anything?style=social)|2024|
|t-rex|Towards Generic Object Detection via Text-Visual Prompt Synergy.|[Github](https://github.com/idea-research/t-rex) ![GitHub Repo stars](https://img.shields.io/github/stars/idea-research/t-rex?style=social)|2024|

### Image/Video Enhancements
| Name | Description | Links | Publish Time|
| ---- | ----------------------------- | --- | --- |
| CodeFormer | Towards Robust Blind Face Restoration with Codebook Lookup Transformer (NeurIPS 2022) . By S-Lab, Nanyang Technological University| [Github](https://github.com/sczhou/CodeFormer) ![GitHub Repo stars](https://img.shields.io/github/stars/sczhou/CodeFormer?style=social) | 2023 |

### Super-Resolution
| Name | Description | Links | Publish Time|
| ---- | ----------------------------- | --- | --- |
| Upscale-A-Video |  Upscale-A-Video is a diffusion-based model that upscales videos by taking the low-resolution video and text prompts as inputs. S-Lab, Nanyang Technological University|[Github](https://github.com/sczhou/Upscale-A-Video) ![GitHub Repo stars](https://img.shields.io/github/stars/sczhou/Upscale-A-Video?style=social)|2023|
| ComfyUI-SUPIR |SUPIR upscaling wrapper for ComfyUI| [Github](https://github.com/kijai/ComfyUI-SUPIR) ![GitHub Repo stars](https://img.shields.io/github/stars/kijai/ComfyUI-SUPIR?style=social) |2024|
| APISR |APISR: Anime Production Inspired Real-World Anime Super-Resolution (CVPR 2024). APISR aims at restoring and enhancing low-quality low-resolution anime images and video sources with various degradations from real-world scenarios.|[Github](https://github.com/Kiteretsu77/APISR)  ![GitHub Repo stars](https://img.shields.io/github/stars/Kiteretsu77/APISR?style=social) |2024|

### Virtual Try-On
| Name | Description | Links | Publish Time|
| ---- | ----------------------------- | --- | --- |
| OutfitAnyone |  Outfit Anyone: Ultra-high quality virtual try-on for Any Clothing and Any Person. Institute for Intelligent Computing, Alibaba Group|[Github](https://github.com/HumanAIGC/OutfitAnyone) ![GitHub Repo stars](https://img.shields.io/github/stars/HumanAIGC/OutfitAnyone?style=social)|2023|
| OOTDiffusion | Official implementation of OOTDiffusion: Outfitting Fusion based Latent Diffusion for Controllable Virtual Try-on |[Github](https://github.com/levihsu/OOTDiffusion) ![GitHub Repo stars](https://img.shields.io/github/stars/levihsu/OOTDiffusion?style=social) Demo:https://ootd.ibot.cn/|2024|

### AI Muisc Generation
| Name | Description | Links | Publish Time|
| ---- | ----------------------------- | --- | --- |
| StemGen |  StemGen: A music generation model that listens, ByteDance Inc|[Project Website](https://julian-parker.github.io/stemgen/) |2023|

### RAG(Retrieval-Augmented Generation)
| Name | Description | Links | Publish Time|
| ---- | ----------------------------- | --- | --- |
|Retrieval-Augmented Generation for Large Language Models: A Survey| Shanghai Research Institute for Intelligent Autonomous Systems|[URL](https://arxiv.org/abs/2312.10997)|2023|

### OCR
| Name | Description | Links | Publish Time|
| ---- | ----------------------------- | --- | --- |
|surya|Surya is a multilingual document OCR toolkit. It can do: Accurate line-level text detection|[Github](https://github.com/VikParuchuri/surya) ![GitHub Repo stars](https://img.shields.io/github/stars/VikParuchuri/surya?style=social)|2024|

### Visual Speech Processing
| Name | Description | Links | Publish Time|
| ---- | ----------------------------- | --- | --- |
|sally-sh/vsp-llm|Visual Speech Processing incorporated with LLMs <br>paper：https://arxiv.org/abs/2402.15151v1|[Github](https://github.com/sally-sh/vsp-llm) ![GitHub Repo stars](https://img.shields.io/github/stars/sally-sh/vsp-llm?style=social)|2024|

### 3D Human Pose Estimation
| Name | Description | Links | Publish Time|
| ---- | ----------------------------- | --- | --- |
|NationalGAILab/HoT|Hourglass Tokenizer for Efficient Transformer-Based 3D Human Pose Estimation|[Github](https://github.com/NationalGAILab/HoT) ![GitHub Repo stars](https://img.shields.io/github/stars/NationalGAILab/HoT?style=social)|2024|

### Computer Vision
| Name | Description | Links | Publish Time|
| ---- | ----------------------------- | --- | --- |
|GeneOH-Diffusion| Towards Generalizable Hand-Object Interaction Denoising via Denoising Diffusion| [Github](https://github.com/Meowuu7/GeneOH-Diffusion) ![GitHub Repo stars](https://img.shields.io/github/stars/Meowuu7/GeneOH-Diffusion?style=social)|2024|
|Efficient-Large-Model/VILA|VILA - a multi-image visual language model with training, inference and evaluation recipe, deployable from cloud to edge (Jetson Orin and laptops)|[Github](https://github.com/Efficient-Large-Model/VILA) ![GitHub Repo stars](https://img.shields.io/github/stars/Efficient-Large-Model/VILA?style=social)|2024|

### Star History

[![Star 历史记录](https://api.star-history.com/svg?repos=ikaijua/Awesome-AIResearch&type=Date)](https://star-history.com/#ikaijua/Awesome-AIResearch&Date)


<a href="https://www.buymeacoffee.com/AwesomeAITools" target="_blank"><img src="https://cdn.buymeacoffee.com/buttons/default-orange.png" alt="Buy Me A Coffee" height="41" width="174"></a>

如果您喜欢这个项目，可以赞赏一下支持我们，谢谢您的支持！

<img src="https://github.com/ikaijua/Awesome-AITools/assets/126046795/76df3881-cf88-4767-96e0-157a2bb8f585" width="20%" height="20%" />   
